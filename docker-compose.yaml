services:
  backend:
    image: shop_service
    container_name: shop_service
    build:
      context: ./catalog
    ports:
      - "8080:8080"
    environment:
      - ELASTICSEARCH_HOST=elasticsearch:9200
    depends_on:
      postgres-catalog:
        condition: service_healthy
      kafka:
        condition: service_healthy
  api-gateway:
    build: ./api-gateway
    container_name: api-gateway
    env_file:
      - ./api-gateway/.env
    ports:
      - "8000:8000"
  # depends_on:
  #     - auth
  #     - backend

  auth:
    build: ./auth
    container_name: auth_service
    ports:
      - "5000:8000"
    environment:
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=postgres
      - POSTGRES_HOST=postgres-auth
      - POSTGRES_PORT=5432
      - POSTGRES_DB=auth_db
      - JWT_SECRET_KEY=your-secret-key-here
    depends_on:
      postgres-auth:
        condition: service_healthy

  postgres-auth:
    image: postgres
    container_name: postgres-auth
    restart: always
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
      POSTGRES_DB: auth_db
    ports:
      - "5433:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres -d auth_db"]
      interval: 10s
      timeout: 5s
      retries: 5
    volumes:
      - './auth/migrations/:/docker-entrypoint-initdb.d/'

  postgres-catalog:
    image: postgres
    container_name: postgres-catalog
    restart: always
    environment:
      POSTGRES_USER: user
      POSTGRES_PASSWORD: psswd
      POSTGRES_DB: postgresDB
      PGPORT: 5432
    ports:
      - "5432:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U user -d postgresDB"]
      interval: 10s
      timeout: 5s
      retries: 5
    volumes:
      - './catalog/migrations/:/docker-entrypoint-initdb.d/'

  zookeeper:
    image: confluentinc/cp-zookeeper:7.6.0
    container_name: zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    ports:
      - "2181:2181"

  kafka:
    image: confluentinc/cp-kafka:7.6.0
    container_name: kafka
    ports:
      - "9092:9092"
    depends_on:
      - zookeeper
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
    healthcheck:
      test: ["CMD-SHELL", "kafka-topics --bootstrap-server kafka:9092 --list || exit 1"]
      interval: 10s
      timeout: 10s
      retries: 10

  consumer:
    build: ./consumer  
    container_name: kafka-consumer
    depends_on:
      kafka:
        condition: service_healthy
    environment:
      KAFKA_BOOTSTRAP_SERVERS: kafka:9092
      KAFKA_TOPIC: user-events
    restart: always
    networks:
      - default

  elasticsearch:
    image: elasticsearch:7.17.14
    container_name: elasticsearch
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
      - bootstrap.memory_lock=true
    ulimits:
      memlock:
        soft: -1
        hard: -1
    ports:
      - "9200:9200"
    volumes:
      - elasticsearch-data:/usr/share/elasticsearch/data
    healthcheck:
      test: ["CMD-SHELL", "curl -s http://localhost:9200/_cluster/health | grep -q 'status.*yellow'"]
      interval: 30s
      timeout: 10s
      retries: 5
    networks:
      - default
    
  prometheus:
    image: prom/prometheus
    container_name: prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml
      
  grafana:
    image: grafana/grafana
    container_name: grafana
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_USER=admin
      - GF_SECURITY_ADMIN_PASSWORD=admin
      - GF_INSTALL_PLUGINS=vertamedia-clickhouse-datasource
    volumes:
      - ./grafana/provisioning:/etc/grafana/provisioning
      # - grafana-data:/var/lib/grafana
    depends_on:
      - prometheus
      - clickhouse-server

  etl:
   build: ./etl
   container_name: product-etl
   depends_on:
     kafka:
       condition: service_healthy
   environment:
     KAFKA_BOOTSTRAP_SERVERS: kafka:9092
     KAFKA_TOPIC: product-events
     ELASTICSEARCH_HOST: elasticsearch:9200
   restart: always
   networks:
     - default

  comment-etl:
   build: ./etl
   container_name: comment-etl
   depends_on:
     kafka:
       condition: service_healthy
   environment:
     KAFKA_BOOTSTRAP_SERVERS: kafka:9092
     KAFKA_TOPIC: comment-events
     ELASTICSEARCH_HOST: elasticsearch:9200
   command: python comment_etl.py
   restart: always
   networks:
     - default

  clickhouse-server:
    image: clickhouse/clickhouse-server:latest
    container_name: clickhouse-server
    ports:
      - "8123:8123"   # HTTP интерфейс
      - "9000:9000"   # Native интерфейс (для клиентов)
    volumes:
      - clickhouse-data:/var/lib/clickhouse
#      - ./clickhouse/config.xml:/etc/clickhouse/config.xml:ro
#      - ./clickhouse/users.xml:/etc/clickhouse/users.xml:ro
    ulimits:
      nofile:
        soft: 262144
        hard: 262144

volumes:
  elasticsearch-data:
  clickhouse-data:

networks:
  default:
    driver: bridge
